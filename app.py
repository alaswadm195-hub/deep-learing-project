# app.py
import io
import cv2
import torch
import numpy as np
from PIL import Image
from fastapi import FastAPI, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from pathlib import Path

# Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ ÙƒÙ„Ø§Ø³Ø§Øª Ù…Ø´Ø±ÙˆØ¹Ù†Ø§
from model import AgeGenderModel
from preprocessing import ImagePreprocessor, FaceDetector

# ===========================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø³ÙŠØ±ÙØ± ÙˆØ§Ù„Ù…ÙˆØ¯ÙŠÙ„
# ===========================
app = FastAPI(title="Age & Gender AI API")

# Ø§Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ù…ÙˆÙ‚Ø¹ (Ø§Ù„ÙØ±ÙˆÙ†Øª Ø¥Ù†Ø¯) Ø¥Ù†Ù‡ ÙŠÙƒÙ„Ù… Ø§Ù„Ø³ÙŠØ±ÙØ±
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# ØªØ£ÙƒØ¯ Ù…Ù† Ù…Ø³Ø§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨ØªØ§Ø¹Ùƒ Ù‡Ù†Ø§ ğŸ‘‡
MODEL_PATH = Path("checkpoints/best_model.pth")

# Ù…ØªØºÙŠØ±Ø§Øª Ø¹Ø§Ù…Ø© Ù‡Ù†Ø­Ù…Ù„Ù‡Ø§ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
model = None
preprocessor = None
face_detector = None

# ===========================
# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
# ===========================
def ensure_tensor_bchw(t):
    """Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ØªÙ†Ø³ÙˆØ± (Ø²ÙŠ Ø§Ù„Ù„ÙŠ ÙÙŠ predict_one.py)"""
    if not torch.is_tensor(t): t = torch.from_numpy(t)
    if t.dim() == 3:
        if t.shape[2] == 3: t = t.permute(2, 0, 1)
        elif t.shape[0] == 3: pass
        else: t = t.permute(2, 0, 1) if t.shape[-1] == 3 else t
    elif t.dim() == 4:
        if t.shape[1] == 3: pass
        elif t.shape[-1] == 3: t = t.permute(0, 3, 1, 2)
    if t.dim() == 3: t = t.unsqueeze(0)
    t = t.float()
    return t

@app.on_event("startup")
async def load_ai_models():
    """Ù‡Ù†Ø§ Ø¨Ù†Ø­Ù…Ù„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ø£ÙˆÙ„ Ù…Ø§ Ø§Ù„Ø³ÙŠØ±ÙØ± ÙŠØ´ØªØºÙ„ Ø¹Ø´Ø§Ù† Ø§Ù„Ø³Ø±Ø¹Ø©"""
    global model, preprocessor, face_detector
    print("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª...")
    
    # 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
    model = AgeGenderModel(pretrained=False)
    try:
        state = torch.load(MODEL_PATH, map_location=DEVICE)
        if isinstance(state, dict) and 'model_state_dict' in state:
            model.load_state_dict(state['model_state_dict'])
        else:
            model.load_state_dict(state)
        model.to(DEVICE)
        model.eval()
        print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­.")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„: {e}")
        print("ØªØ£ÙƒØ¯ Ù…Ù† Ù…Ø³Ø§Ø± Ù…Ù„Ù best_model.pth")

    # 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª
    preprocessor = ImagePreprocessor(target_size=(224, 224))
    # Ø§Ø³ØªØ®Ø¯Ù… 'mtcnn' Ù„Ù„Ø¯Ù‚Ø© Ø£Ùˆ None Ù„Ù„Ø³Ø±Ø¹Ø© Ù„Ùˆ ØµÙˆØ±Ùƒ Ù…Ù‚ØµÙˆØµØ© Ø¬Ø§Ù‡Ø²Ø©
    face_detector = FaceDetector(method='mtcnn', device=str(DEVICE)) 
    print("ğŸš€ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø¬Ø§Ù‡Ø² Ù„Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„ØµÙˆØ±!")

# ===========================
# Ù†Ù‚Ø·Ø© Ø§Ù„Ø§ØªØµØ§Ù„ (API Endpoint)
# ===========================
@app.post("/predict")
async def predict_image(file: UploadFile = File(...)):
    """Ø¨ÙŠØ³ØªÙ‚Ø¨Ù„ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙˆÙŠØ±Ø¬Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© JSON"""
    
    # 1. Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„Ø·Ù„Ø¨
    contents = await file.read()
    nparr = np.frombuffer(contents, np.uint8)
    img_bgr = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    
    if img_bgr is None:
        return {"error": "Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙ‚ Ù„ÙŠØ³ ØµÙˆØ±Ø© ØµØ§Ù„Ø­Ø©"}

    # 2. ÙƒØ´Ù Ø§Ù„ÙˆØ¬Ù‡ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
    face_t = face_detector.detect_and_crop_face(img_bgr)
    warning = None
    if face_t is None:
        warning = "Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù ÙˆØ¬Ù‡ØŒ Ø³ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©."
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø© Ù„ØªÙ†Ø³ÙˆØ±
        face_input = torch.from_numpy(img_bgr)
    else:
        face_input = face_t # Ø¯Ù‡ ØªÙ†Ø³ÙˆØ± Ø¬Ø§Ù‡Ø² Ù…Ù† Ø§Ù„ÙƒØ§Ø´Ù

    # 3. Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
    processed = preprocessor.preprocess(face_input)
    input_tensor = ensure_tensor_bchw(processed).to(DEVICE)

    # 4. Ø§Ù„ØªÙˆÙ‚Ø¹ (Inference)
    with torch.no_grad():
        pred_age, pred_gender = model(input_tensor)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙŠÙ…
        age_val = round(pred_age.item(), 1)
        
        probs = torch.softmax(pred_gender, dim=1)
        gender_idx = torch.argmax(probs, dim=1).item()
        gender_prob = probs[0][gender_idx].item()
        
        gender_label = "Male" if gender_idx == 0 else "Female"

    # 5. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø¯
    return {
        "age": age_val,
        "gender": gender_label,
        "confidence": round(gender_prob * 100, 2),
        "warning": warning
    }